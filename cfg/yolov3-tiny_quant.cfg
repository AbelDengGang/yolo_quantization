[net]
# Testing
batch=1
subdivisions=1
# Training
# batch=64
# subdivisions=2
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 270200
policy=steps
steps=400000,450000
scales=.1,.1

# input_calibration = 15.7342, 4.41852, 9.17237, 9.70713, 13.1849, 14.9823, 15.1913, 8.62978, 15.7353, 15.6297, 15.6939, 15.4093, 15.8055, 16
input_calibration = 15.0226, 15.0226, 14.8113, 14.2604, 14.6867, 15.0226, 15.0226, 15.8132, 15.8132, 15.8132, 15.0226, 15.0226, 15.8132, 16

# "quantized" is for nvidia quantization for QUANTIZATION in makefile
# "weight_quant" and "activ_quant" are for google quantization for QUANTIZATION_GOOGLE in makefile
[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky
quantized=1
# quant_stop=1

[maxpool]
size=2
stride=2
quantized=1
# quant_stop=1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky
quantized=1
# quant_stop=1

[maxpool]
size=2
stride=2
quantized=1
# quant_stop=1

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky
quantized=1
# quant_stop=1

#-------------------------------
[maxpool]
size=2
stride=2
quantized=1
# quant_stop=1

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky
quantized=1

[maxpool]
size=2
stride=2
quantized=1
# quant_stop=1

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
quantized=1
# quant_stop=1

[maxpool]
size=2
stride=2
quantized=1
# quant_stop=1

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
quantized=1
# quant_stop=1

#-------------------------------
[maxpool]
size=2
stride=1
quantized=1

[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
activation=leaky
quantized=1
# quant_stop=1

###########

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=leaky
quantized=1
quant_stop=1

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=leaky
# quantized=1
# quant_stop=1

[convolutional]
size=1
stride=1
pad=1
filters=30
activation=linear
# quantized=1

[yolo]
mask = 3,4,5
anchors = 25,39, 29,88, 405,102, 407,109,408,113,420,129
classes=5
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1

[route]
layers = -4
quantized=1
# quant_stop=1

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=leaky
quantized=1
# quant_stop=1

[upsample]
stride=2
quantized=1
# quant_stop=1

[route]
layers = -1, 8
quantized=1
first_time=1
quant_stop=1

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky
# quantized=1
# first_time=1

[convolutional]
size=1
stride=1
pad=1
filters=30
activation=linear
# quantized=1

[yolo]
mask = 0,1,2
anchors = 25,39, 29,88, 405,102, 407,109,408,113,420,129
classes=5
num=6
jitter=.3
ignore_thresh = .7
truth_thresh = 1
random=1
